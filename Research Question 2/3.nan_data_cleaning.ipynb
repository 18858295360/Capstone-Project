{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95fed5b-b5c2-4030-9d1a-9f28c2291fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Lasso-selected important features: ['los_x', 'positiveculture', 'gcs', 'gcsmotor', 'lactate', 'bloodureanitrogen', 'hemoglobin', 'intnormalisedratio', 'albumin', 'chloride', 'hematocrit', 'age_years', 'insurance_Medicare']\n",
      "Final feature list after manually adding mandatory features: ['los_x', 'positiveculture', 'gcs', 'gcsmotor', 'lactate', 'bloodureanitrogen', 'hemoglobin', 'intnormalisedratio', 'albumin', 'chloride', 'hematocrit', 'age_years', 'insurance_Medicare', 'gcsverbal', 'admission_location_EMERGENCY ROOM ADMIT', 'admission_location_PHYS REFERRAL/NORMAL DELI', 'admission_location_CLINIC REFERRAL/PREMATURE', 'admission_location_TRANSFER FROM HOSP/EXTRAM', 'admission_type_URGENT', 'is_weekend_admission']\n",
      "NaN Value Statistics After Filling:\n",
      "gcsmotor         75\n",
      "lactate       15812\n",
      "hemoglobin     9493\n",
      "albumin       18060\n",
      "gcsverbal        67\n",
      "dtype: int64\n",
      "Final dataset shape: (20101, 21)\n",
      "The cleaned data with long-term mortality flag as 'expire_flag' has been exported to /root/DATA/cleaned_cox_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load and select the first ICU admission record for each patient\n",
    "chunksize = 50000\n",
    "sample_fraction = 1\n",
    "selected_columns = [\n",
    "    'subject_id_x', 'age_years', 'admission_type', 'admission_location', \n",
    "    'discharge_location', 'insurance', 'marital_status', 'ethnicity', 'diagnosis', \n",
    "    'positiveculture', 'ab_name', 'antibioticresistance', \n",
    "    'gcs', 'gcseyes', 'gcsmotor', 'gcsverbal', 'endotrachflag', 'neutrophil', \n",
    "    'creactiveprotein', 'whitebloodcell', 'partialpressureo2', 'bicarbonate', \n",
    "    'lactate', 'troponin', 'bloodureanitrogen', 'creatinine', 'alaninetransaminase', \n",
    "    'aspartatetransaminase', 'hemoglobin', 'intnormalisedratio', 'platelets', \n",
    "    'albumin', 'chloride', 'glucose', 'sodium', 'bilirubin', 'hematocrit', \n",
    "    'first_careunit', 'last_careunit', 'los_x', 'intime_x', 'outtime_x', \n",
    "    'expire_flag'\n",
    "]\n",
    "\n",
    "# Load and filter the first ICU admission record for each patient\n",
    "filtered_chunks = []\n",
    "for chunk in pd.read_csv('/root/DATA/filtered_merged_data.csv', usecols=selected_columns, chunksize=chunksize, low_memory=False):\n",
    "    chunk_sample = chunk.sample(frac=sample_fraction, random_state=42)\n",
    "    chunk_sorted = chunk_sample.sort_values('intime_x').drop_duplicates(subset='subject_id_x', keep='first')\n",
    "    filtered_chunks.append(chunk_sorted)\n",
    "\n",
    "filtered_data = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Add a new column for is_weekend_admission based on intime_x\n",
    "filtered_data['intime_x'] = pd.to_datetime(filtered_data['intime_x'], errors='coerce')\n",
    "filtered_data['is_weekend_admission'] = filtered_data['intime_x'].dt.weekday >= 5  # 周六和周日为 True\n",
    "\n",
    "# Remove datetime columns before scaling\n",
    "filtered_data = filtered_data.drop(columns=['intime_x', 'outtime_x'])\n",
    "\n",
    "# 2. Separate features and target (using long-term mortality with 'expire_flag')\n",
    "X = filtered_data.drop(columns=['expire_flag', 'subject_id_x'], errors='ignore')\n",
    "y = filtered_data['expire_flag']\n",
    "\n",
    "# 3. Fill missing values\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'float64':\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "    elif X[col].dtype == 'object':\n",
    "        X[col] = X[col].fillna('Unknown')\n",
    "\n",
    "# 4. Encode categorical variables and standardize\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# 5. Use Lasso for feature selection\n",
    "lasso = Lasso(alpha=0.01, random_state=42)\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# 6. Filter Lasso-selected important features\n",
    "pattern = re.compile(r'(_\\d{4}-\\d{2}-\\d{2})|(_[A-Z]{2,}\\d*)')\n",
    "lasso_selected_features = [feat for feat in X_encoded.columns[(lasso.coef_ != 0)] if not pattern.search(feat)]\n",
    "print(\"Filtered Lasso-selected important features:\", lasso_selected_features)\n",
    "\n",
    "# Manually ensure these important features are included, including dummy variables\n",
    "mandatory_features = [\n",
    "    'age_years', 'gcsverbal', 'gcsmotor', 'bloodureanitrogen',\n",
    "    'admission_location_EMERGENCY ROOM ADMIT', 'admission_location_PHYS REFERRAL/NORMAL DELI',\n",
    "    'admission_location_CLINIC REFERRAL/PREMATURE', 'admission_location_TRANSFER FROM HOSP/EXTRAM',\n",
    "    'admission_type_URGENT', 'is_weekend_admission'\n",
    "]\n",
    "\n",
    "# Add each mandatory feature if it’s missing\n",
    "for feature in mandatory_features:\n",
    "    if feature not in lasso_selected_features:\n",
    "        lasso_selected_features.append(feature)\n",
    "\n",
    "print(\"Final feature list after manually adding mandatory features:\", lasso_selected_features)\n",
    "\n",
    "# 7. Generate the final encoded dataset with selected features, ensuring column consistency\n",
    "final_data_encoded = pd.get_dummies(filtered_data, drop_first=True)\n",
    "for col in lasso_selected_features:\n",
    "    if col not in final_data_encoded.columns:\n",
    "        final_data_encoded[col] = 0  # Add missing columns and fill with 0\n",
    "\n",
    "# Include 'expire_flag' as the target variable in the final dataset\n",
    "final_data_selected = final_data_encoded[lasso_selected_features + ['expire_flag']]\n",
    "\n",
    "# 8. Fill NaN values for specific columns\n",
    "for col in ['bloodureanitrogen', 'intnormalisedratio', 'chloride', 'hematocrit']:\n",
    "    if col in final_data_selected.columns:\n",
    "        final_data_selected[col].fillna(final_data_selected[col].median(), inplace=True)\n",
    "\n",
    "# 9. Check for NaN values\n",
    "nan_summary = final_data_selected.isna().sum()\n",
    "print(\"NaN Value Statistics After Filling:\")\n",
    "print(nan_summary[nan_summary > 0])\n",
    "\n",
    "# Check the final shape of the data\n",
    "print(\"Final dataset shape:\", final_data_selected.shape)\n",
    "\n",
    "# Save the final data\n",
    "output_path = '/root/DATA/cleaned_cox_dataset.csv'\n",
    "final_data_selected.to_csv(output_path, index=False)\n",
    "print(f\"The cleaned data with long-term mortality flag as 'expire_flag' has been exported to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
